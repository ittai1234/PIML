{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pysindy as ps\n",
    "import os\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.fft import fft, ifft\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import MultiTaskLassoCV, LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from typing import Tuple, Any, Iterable, Dict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Lorenz Data2\n",
    "train_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data2\\train_lorenz_subset.npy\"\n",
    "test_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data2\\test_lorenz_subset.npy\"\n",
    "val_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data2\\validate_lorenz_subset.npy\"\n",
    "train_data = np.load(train_file_path)\n",
    "test_data = np.load(test_file_path)\n",
    "val_data = np.load(val_file_path)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Lorenz Data1\n",
    "train_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data1\\lorenz_train.npy\"\n",
    "test_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data1\\lorenz_test.npy\"\n",
    "val_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data1\\lorenz_val.npy\"\n",
    "train_data = np.load(train_file_path)\n",
    "test_data = np.load(test_file_path)\n",
    "val_data = np.load(val_file_path)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def prepare_dataloader(data, batch_size):\n",
    "    inputs = torch.tensor(data[:, :-1, :], dtype=torch.float32)  # All but last timestep as input\n",
    "    targets = torch.tensor(data[:, -1, :], dtype=torch.float32)  # Last timestep as target\n",
    "    dataset = TensorDataset(inputs, targets)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader = prepare_dataloader(train_data, batch_size)\n",
    "val_loader = prepare_dataloader(val_data, batch_size)\n",
    "test_loader = prepare_dataloader(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedConvFNO(nn.Module):\n",
    "    def __init__(self, modes, width, conv_filters):\n",
    "        super(AdvancedConvFNO, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(3, conv_filters, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(conv_filters, conv_filters, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(conv_filters, self.width, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fourier Neural Operator\n",
    "        self.fc0 = nn.Linear(self.width, self.width)\n",
    "        self.fc1 = nn.Linear(self.width, self.width)\n",
    "        self.fc2 = nn.Linear(self.width, 3)  # Output (x, y, z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize, seq_len, channels = x.shape\n",
    "\n",
    "        # Apply convolutions\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch, channels, seq_len)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.permute(0, 2, 1)  # Back to (batch, seq_len, channels)\n",
    "\n",
    "        # Fourier Neural Operator\n",
    "        x = self.fc0(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x[:, -1, :])  # Use the last timestep\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SINDy for Post-Training Analysis\n",
    "def apply_sindy(train_data_flat, test_data_flat, dt):\n",
    "    x_train = train_data_flat[:-1]\n",
    "    dx_train = (train_data_flat[1:] - train_data_flat[:-1]) / dt\n",
    "    x_test = test_data_flat[:-1]\n",
    "    dx_test = (test_data_flat[1:] - test_data_flat[:-1]) / dt\n",
    "\n",
    "    # Define the SINDy model\n",
    "    feature_library = ps.PolynomialLibrary(degree=3)\n",
    "    optimizer = ps.STLSQ(threshold=0.1)\n",
    "    sindy_model = ps.SINDy(feature_library=feature_library, optimizer=optimizer)\n",
    "\n",
    "    # Fit and evaluate\n",
    "    sindy_model.fit(x_train, t=dt, x_dot=dx_train)\n",
    "    print(\"\\nSINDy Discovered Equations:\")\n",
    "    sindy_model.print()\n",
    "    print(f\"SINDy Test Score: {sindy_model.score(x_test, t=dt, x_dot=dx_test):.4f}\")\n",
    "\n",
    "# Accuracy Calculation\n",
    "def calculate_accuracy(outputs, targets, tolerance=0.1):\n",
    "    correct = torch.sum(torch.abs(outputs - targets) < tolerance).item()\n",
    "    total = targets.numel()\n",
    "    return correct / total * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Accuracy\n",
    "def train_and_evaluate(model, train_loader, val_loader, epochs, learning_rate):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += torch.sum(torch.abs(outputs - targets) < 0.1).item()\n",
    "            train_total += targets.numel()\n",
    "\n",
    "        train_accuracy = train_correct / train_total * 100\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += torch.sum(torch.abs(outputs - targets) < 0.1).item()\n",
    "                val_total += targets.numel()\n",
    "\n",
    "        val_accuracy = val_correct / val_total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'modes': [16, 32],\n",
    "    'width': [64, 128],\n",
    "    'conv_filters': [16, 32],\n",
    "    'learning_rate': [0.001, 0.0005],\n",
    "    'epochs': [50]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Grid Search for Hyperparameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params: {params}\")\n",
    "    model = AdvancedConvFNO(modes=params['modes'], width=params['width'], conv_filters=params['conv_filters'])\n",
    "    val_loss = train_and_evaluate(model, train_loader, val_loader,\n",
    "                                  epochs=params['epochs'],\n",
    "                                  learning_rate=params['learning_rate'])\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Params: {best_params}, Best Validation Loss: {best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_sindy(train_data_flat, test_data_flat, dt):\n",
    "    x_train = train_data_flat[:-1]\n",
    "    dx_train = (train_data_flat[1:] - train_data_flat[:-1]) / dt\n",
    "    x_test = test_data_flat[:-1]\n",
    "    dx_test = (test_data_flat[1:] - test_data_flat[:-1]) / dt\n",
    "\n",
    "    # Define multiple libraries to test\n",
    "    polynomial_degrees = [2, 3, 4]\n",
    "    thresholds = [0.05, 0.1, 0.2]\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    best_params = {}\n",
    "\n",
    "    for degree in polynomial_degrees:\n",
    "        for threshold in thresholds:\n",
    "            print(f\"Testing SINDy with Polynomial Degree: {degree}, Threshold: {threshold}\")\n",
    "\n",
    "            # Define the SINDy model\n",
    "            feature_library = ps.PolynomialLibrary(degree=degree) + ps.FourierLibrary(n_frequencies=3)\n",
    "            optimizer = ps.STLSQ(threshold=threshold)\n",
    "            sindy_model = ps.SINDy(\n",
    "                optimizer=optimizer,\n",
    "                feature_library=feature_library,\n",
    "                differentiation_method=ps.FiniteDifference()\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            sindy_model.fit(x_train, t=dt, x_dot=dx_train)\n",
    "            score = sindy_model.score(x_test, t=dt, x_dot=dx_test)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_model = sindy_model\n",
    "                best_score = score\n",
    "                best_params = {\"degree\": degree, \"threshold\": threshold}\n",
    "\n",
    "    # Print the best model's equations\n",
    "    print(\"\\nBest SINDy Model:\")\n",
    "    best_model.print()\n",
    "    print(f\"Best SINDy Test Score: {best_score:.4f}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_score = best_model.score(x_test, t=dt, x_dot=dx_test)\n",
    "    print(f\"Final SINDy Test Score: {test_score:.4f}\")\n",
    "\n",
    "    return best_model, best_params, test_score\n",
    "\n",
    "#need to apply in another way\n",
    "\n",
    "# Apply SINDy\n",
    "train_data_flat = train_data.reshape(-1, train_data.shape[-1])  # Flatten training data\n",
    "test_data_flat = test_data.reshape(-1, test_data.shape[-1])  # Flatten test data\n",
    "best_sindy_model, best_params, test_score = advanced_sindy(train_data_flat, test_data_flat, dt=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_ground_truth(model, sindy_model, test_data, dt, device):\n",
    "    # Prepare data for visualization\n",
    "    test_inputs = torch.tensor(test_data[:, :-1, :], dtype=torch.float32).to(device)\n",
    "    ground_truth = test_data[:, -1, :]\n",
    "\n",
    "    # Model predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_predictions = model(test_inputs).cpu().numpy()\n",
    "\n",
    "    # SINDy predictions\n",
    "    test_data_flat = test_data.reshape(-1, test_data.shape[-1])\n",
    "    sindy_inputs = test_data_flat[:-1]\n",
    "    sindy_predictions = sindy_model.predict(sindy_inputs)\n",
    "\n",
    "    # Visualize ground truth, model predictions, and SINDy predictions\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Ground Truth\n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    ax1.plot(ground_truth[:, 0], ground_truth[:, 1], ground_truth[:, 2], 'g', label=\"Ground Truth\")\n",
    "    ax1.set_title(\"Ground Truth\")\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "    ax1.set_zlabel(\"Z\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Model Predictions\n",
    "    ax2 = fig.add_subplot(132, projection='3d')\n",
    "    ax2.plot(model_predictions[:, 0], model_predictions[:, 1], model_predictions[:, 2], 'b', label=\"Model Predictions\")\n",
    "    ax2.set_title(\"Model Predictions\")\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    ax2.set_zlabel(\"Z\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # SINDy Predictions\n",
    "    ax3 = fig.add_subplot(133, projection='3d')\n",
    "    ax3.plot(sindy_predictions[:, 0], sindy_predictions[:, 1], sindy_predictions[:, 2], 'r', label=\"SINDy Predictions\")\n",
    "    ax3.set_title(\"SINDy Predictions\")\n",
    "    ax3.set_xlabel(\"X\")\n",
    "    ax3.set_ylabel(\"Y\")\n",
    "    ax3.set_zlabel(\"Z\")\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs ground truth in 3D\n",
    "plot_predictions_vs_ground_truth(best_model, best_sindy_model, test_data, dt=0.01, device=device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
