{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import optuna\n",
    "from typing import Tuple, Any, Iterable, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Pendulum Dynamics\n",
    "def double_pendulum(t, y, l1, l2, m1, m2, g):\n",
    "    theta1, z1, theta2, z2 = y\n",
    "    delta = theta2 - theta1\n",
    "    denom1 = (m1 + m2) * l1 - m2 * l1 * np.cos(delta) ** 2\n",
    "    denom2 = (l2 / l1) * denom1\n",
    "\n",
    "    dydt = np.zeros_like(y)\n",
    "    dydt[0] = z1\n",
    "    dydt[1] = (\n",
    "        (m2 * l1 * z1 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + m2 * g * np.sin(theta2) * np.cos(delta)\n",
    "         + m2 * l2 * z2 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta1))\n",
    "        / denom1\n",
    "    )\n",
    "    dydt[2] = z2\n",
    "    dydt[3] = (\n",
    "        (-m2 * l2 * z2 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + (m1 + m2) * g * np.sin(theta1) * np.cos(delta)\n",
    "         - (m1 + m2) * l1 * z1 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta2))\n",
    "        / denom2\n",
    "    )\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the datasets size and dt\n",
    "n_pendulums = 2000\n",
    "dt = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Generation\n",
    "def generate_dataset(n_pendulums, dt):\n",
    "    X_data, y_data = [], []\n",
    "    for _ in range(n_pendulums):\n",
    "        l1, l2 = np.random.uniform(0.5, 2.0, 2)\n",
    "        m1, m2 = np.random.uniform(0.5, 2.0, 2)\n",
    "        g = 9.81\n",
    "        y0 = np.random.uniform(-np.pi, np.pi, 4)\n",
    "        t_span = (0, 10)\n",
    "        t_eval = np.linspace(t_span[0], t_span[1], int(10 / dt))\n",
    "\n",
    "        sol = solve_ivp(double_pendulum, t_span, y0, t_eval=t_eval, args=(l1, l2, m1, m2, g), method='RK45')\n",
    "        theta1, z1, theta2, z2 = sol.y\n",
    "\n",
    "        for i in range(len(t_eval) - 1):\n",
    "            current_state = [theta1[i], theta2[i], z1[i], z2[i]]\n",
    "            next_state = [theta1[i + 1], theta2[i + 1], z1[i + 1], z2[i + 1]]\n",
    "            X_data.append(current_state)\n",
    "            y_data.append(next_state)\n",
    "\n",
    "    X_data = torch.tensor(X_data, dtype=torch.float32)\n",
    "    y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = generate_dataset(n_pendulums, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_size = int(0.7 * len(X_data))\n",
    "val_size = int(0.2 * len(X_data))\n",
    "test_size = len(X_data) - train_size - val_size\n",
    "\n",
    "train_X, train_y = X_data[:train_size], y_data[:train_size]\n",
    "val_X, val_y = X_data[train_size:train_size + val_size], y_data[train_size:train_size + val_size]\n",
    "test_X, test_y = X_data[train_size + val_size:], y_data[train_size + val_size:]\n",
    "\n",
    "# Convert to TensorDataset\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "val_dataset = TensorDataset(val_X, val_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy-Based Loss Function\n",
    "def energy_loss(pred_coords, pred_coords_dot, true_coords, true_coords_dot, l1, l2, m1, m2, g):\n",
    "    def compute_energy(coords, coords_dot):\n",
    "        theta1, theta2 = coords[:, 0], coords[:, 1]\n",
    "        theta1_dot, theta2_dot = coords_dot[:, 0], coords_dot[:, 1]\n",
    "\n",
    "        T1 = 0.5 * m1 * (l1 ** 2) * (theta1_dot ** 2)\n",
    "        T2 = 0.5 * m2 * (\n",
    "            (l1 ** 2) * (theta1_dot ** 2)\n",
    "            + (l2 ** 2) * (theta2_dot ** 2)\n",
    "            + 2 * l1 * l2 * theta1_dot * theta2_dot * torch.cos(theta2 - theta1)\n",
    "        )\n",
    "        V1 = -m1 * g * l1 * torch.cos(theta1)\n",
    "        V2 = -m2 * g * (l1 * torch.cos(theta1) + l2 * torch.cos(theta2))\n",
    "\n",
    "        T = T1 + T2\n",
    "        V = V1 + V2\n",
    "        return T + V\n",
    "\n",
    "    pred_energy = compute_energy(pred_coords, pred_coords_dot)\n",
    "    true_energy = compute_energy(true_coords, true_coords_dot)\n",
    "\n",
    "    return torch.mean((pred_energy - true_energy) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Pendulum LNN Class\n",
    "class LagrangianNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LagrangianNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 1)  # Output the Lagrangian scalar\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublePendulumLNN:\n",
    "    def __init__(self, hidden_dim=128, lr=1e-3):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = LagrangianNN(input_dim=4, hidden_dim=hidden_dim).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        self.criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_state(self, coords, coords_dot, dt):\n",
    "    coords.requires_grad_(True)\n",
    "    coords_dot.requires_grad_(True)\n",
    "\n",
    "    coords_dot_input = torch.cat((coords, coords_dot), dim=1)\n",
    "    L = self.model(coords_dot_input)\n",
    "    accel = self.lagrangian_to_accelerations(coords, coords_dot, L)\n",
    "\n",
    "    k1 = accel\n",
    "    k2 = accel + 0.5 * dt * k1\n",
    "    k3 = accel + 0.5 * dt * k2\n",
    "    k4 = accel + dt * k3\n",
    "\n",
    "    next_coords = coords + dt / 6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    next_coords_dot = coords_dot + accel * dt\n",
    "    return next_coords, next_coords_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrangian_to_accelerations(self, coords, coords_dot, L):\n",
    "    coords.requires_grad_(True)\n",
    "    coords_dot.requires_grad_(True)\n",
    "\n",
    "    dL_dq = torch.autograd.grad(L.sum(), coords, create_graph=True, allow_unused=True)[0]\n",
    "    dL_dq_dot = torch.autograd.grad(L.sum(), coords_dot, create_graph=True, allow_unused=True)[0]\n",
    "\n",
    "    if dL_dq is None or dL_dq_dot is None:\n",
    "        raise ValueError(\"Gradient calculation returned None. Check inputs and computation graph.\")\n",
    "\n",
    "    accel = torch.autograd.grad(dL_dq_dot.sum(), coords_dot, create_graph=True, allow_unused=True)[0] - dL_dq\n",
    "    return accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_loader, val_loader, dt, epochs=100, l1=1.0, l2=1.0, m1=1.0, m2=1.0, g=9.81, freeze=False):\n",
    "    scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
    "        \n",
    "    if freeze:\n",
    "        for param in self.model.net[0].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for coords, true_next_coords in train_loader:\n",
    "            coords, true_next_coords = coords.to(self.device), true_next_coords.to(self.device)\n",
    "            coords, coords_dot = coords[:, :2], coords[:, 2:]\n",
    "            true_coords, true_coords_dot = true_next_coords[:, :2], true_next_coords[:, 2:]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pred_next_coords, pred_next_coords_dot = self.predict_next_state(coords, coords_dot, dt)\n",
    "\n",
    "            loss = (\n",
    "                self.criterion(pred_next_coords, true_coords)\n",
    "                + self.criterion(pred_next_coords_dot, true_coords_dot)\n",
    "                + energy_loss(pred_next_coords, pred_next_coords_dot, true_coords, true_coords_dot, l1, l2, m1, m2, g)\n",
    "            )\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        val_loss = self.evaluate(val_loader, dt, l1, l2, m1, m2, g)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {total_loss / len(train_loader):.6f}, Val Loss: {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, data_loader, dt, l1=1.0, l2=1.0, m1=1.0, m2=1.0, g=9.81):\n",
    "    self.model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for coords, true_next_coords in data_loader:\n",
    "            coords, true_next_coords = coords.to(self.device), true_next_coords.to(self.device)\n",
    "            coords, coords_dot = coords[:, :2], coords[:, 2:]\n",
    "            true_coords, true_coords_dot = true_next_coords[:, :2], true_next_coords[:, 2:]\n",
    "\n",
    "            pred_next_coords, pred_next_coords_dot = self.predict_next_state(coords, coords_dot, dt)\n",
    "\n",
    "            loss = (\n",
    "                self.criterion(pred_next_coords, true_coords)\n",
    "                + self.criterion(pred_next_coords_dot, true_coords_dot)\n",
    "                + energy_loss(pred_next_coords, pred_next_coords_dot, true_coords, true_coords_dot, l1, l2, m1, m2, g)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning and Training\n",
    "def tune_hyperparameters(train_loader, val_loader, dt):\n",
    "    def objective(trial):\n",
    "        hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "        model = DoublePendulumLNN(hidden_dim=hidden_dim, lr=lr)\n",
    "        model.train(train_loader, val_loader, dt, epochs=10)\n",
    "        return model.evaluate(val_loader, dt)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    print(f\"Best Parameters: {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "best_params = tune_hyperparameters(train_loader, val_loader, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning: Reuse model and fine-tune\n",
    "lnn = DoublePendulumLNN(hidden_dim=best_params['hidden_dim'], lr=1e-4)\n",
    "lnn.train(train_loader, val_loader, dt, epochs=50, freeze=True)  # Fine-tuning with frozen layers\n",
    "lnn.train(train_loader, val_loader, dt, epochs=50, freeze=False)  # Unfreeze layers and train further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Test Data\n",
    "test_loss = lnn.evaluate(test_loader, dt)\n",
    "print(f\"Test Loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Double Pendulum as Animation\n",
    "def visualize_double_pendulum(X_data, X_pred, l1=1.0, l2=1.0, save_path=None):\n",
    "    theta1_true = X_data[:, 0].numpy()\n",
    "    theta2_true = X_data[:, 1].numpy()\n",
    "    theta1_pred = X_pred[:, 0].numpy()\n",
    "    theta2_pred = X_pred[:, 1].numpy()\n",
    "\n",
    "    # Compute positions for ground truth\n",
    "    x1_true = l1 * np.sin(theta1_true)\n",
    "    y1_true = -l1 * np.cos(theta1_true)\n",
    "    x2_true = x1_true + l2 * np.sin(theta2_true)\n",
    "    y2_true = y1_true - l2 * np.cos(theta2_true)\n",
    "\n",
    "    # Compute positions for predictions\n",
    "    x1_pred = l1 * np.sin(theta1_pred)\n",
    "    y1_pred = -l1 * np.cos(theta1_pred)\n",
    "    x2_pred = x1_pred + l2 * np.sin(theta2_pred)\n",
    "    y2_pred = y1_pred - l2 * np.cos(theta2_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    line_true, = ax.plot([], [], 'o-', color='blue', label='Ground Truth', lw=2)\n",
    "    line_pred, = ax.plot([], [], 'o-', color='red', label='Prediction', lw=2)\n",
    "    ax.legend()\n",
    "\n",
    "    def init():\n",
    "        line_true.set_data([], [])\n",
    "        line_pred.set_data([], [])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    def update(frame):\n",
    "        line_true.set_data([0, x1_true[frame], x2_true[frame]], [0, y1_true[frame], y2_true[frame]])\n",
    "        line_pred.set_data([0, x1_pred[frame], x2_pred[frame]], [0, y1_pred[frame], y2_pred[frame]])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1_true), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Example Visualization\n",
    "# Test the visualization with ground truth and predictions\n",
    "sample_test_X = test_X[:200]\n",
    "with torch.no_grad():\n",
    "    sample_test_pred = lnn.model(sample_test_X.to(lnn.device)).cpu()\n",
    "visualize_double_pendulum(sample_test_X, sample_test_pred, save_path='comparison_double_pendulum.gif')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
