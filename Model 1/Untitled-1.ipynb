{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pysindy as ps\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "train_file_path = os.path.join('Model 1', 'Data', 'Data for ML Project 1', 'lorenz_train.npy')\n",
    "test_file_path = os.path.join('Model 1', 'Data', 'Data for ML Project 1', 'lorenz_test.npy')\n",
    "val_file_path = os.path.join('Model 1', 'Data', 'Data for ML Project 1', 'lorenz_val.npy')\n",
=======
    "train_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data\\lorenz_train.npy\"\n",
    "test_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data\\lorenz_test.npy\"\n",
    "val_file_path = r\"C:\\Users\\User\\Documents\\GitHub\\PIML\\Data\\Lorenz Data\\lorenz_val.npy\"\n",
>>>>>>> Stashed changes
    "\n",
    "train_data = np.load(train_file_path)\n",
    "test_data = np.load(test_file_path)\n",
    "val_data = np.load(val_file_path)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def prepare_dataloader(data, batch_size):\n",
    "    inputs = torch.tensor(data[:, :-1, :], dtype=torch.float32)  # All but last timestep as input\n",
    "    targets = torch.tensor(data[:, -1, :], dtype=torch.float32)  # Last timestep as target\n",
    "    dataset = TensorDataset(inputs, targets)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader = prepare_dataloader(train_data, batch_size)\n",
    "val_loader = prepare_dataloader(val_data, batch_size)\n",
    "test_loader = prepare_dataloader(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedConvFNO(nn.Module):\n",
    "    def __init__(self, modes, width, conv_filters):\n",
    "        super(AdvancedConvFNO, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(3, conv_filters, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(conv_filters, conv_filters, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(conv_filters, self.width, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fourier Neural Operator\n",
    "        self.fc0 = nn.Linear(self.width, self.width)\n",
    "        self.fc1 = nn.Linear(self.width, self.width)\n",
    "        self.fc2 = nn.Linear(self.width, 3)  # Output (x, y, z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize, seq_len, channels = x.shape\n",
    "\n",
    "        # Apply convolutions\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch, channels, seq_len)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.permute(0, 2, 1)  # Back to (batch, seq_len, channels)\n",
    "\n",
    "        # Fourier Neural Operator\n",
    "        x = self.fc0(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x[:, -1, :])  # Use the last timestep\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SINDy for Post-Training Analysis\n",
    "def apply_sindy(train_data_flat, test_data_flat, dt):\n",
    "    x_train = train_data_flat[:-1]\n",
    "    dx_train = (train_data_flat[1:] - train_data_flat[:-1]) / dt\n",
    "    x_test = test_data_flat[:-1]\n",
    "    dx_test = (test_data_flat[1:] - test_data_flat[:-1]) / dt\n",
    "\n",
    "    # Define the SINDy model\n",
    "    feature_library = ps.PolynomialLibrary(degree=3)\n",
    "    optimizer = ps.STLSQ(threshold=0.1)\n",
    "    sindy_model = ps.SINDy(feature_library=feature_library, optimizer=optimizer)\n",
    "\n",
    "    # Fit and evaluate\n",
    "    sindy_model.fit(x_train, t=dt, x_dot=dx_train)\n",
    "    print(\"\\nSINDy Discovered Equations:\")\n",
    "    sindy_model.print()\n",
    "    print(f\"SINDy Test Score: {sindy_model.score(x_test, t=dt, x_dot=dx_test):.4f}\")\n",
    "\n",
    "# Accuracy Calculation\n",
    "def calculate_accuracy(outputs, targets, tolerance=0.1):\n",
    "    correct = torch.sum(torch.abs(outputs - targets) < tolerance).item()\n",
    "    total = targets.numel()\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Accuracy\n",
    "def train_and_evaluate(model, train_loader, val_loader, epochs, learning_rate):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += torch.sum(torch.abs(outputs - targets) < 0.1).item()\n",
    "            train_total += targets.numel()\n",
    "\n",
    "        train_accuracy = train_correct / train_total * 100\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += torch.sum(torch.abs(outputs - targets) < 0.1).item()\n",
    "                val_total += targets.numel()\n",
    "\n",
    "        val_accuracy = val_correct / val_total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'modes': [16, 32],\n",
    "    'width': [64, 128],\n",
    "    'conv_filters': [16, 32],\n",
    "    'learning_rate': [0.001, 0.0005],\n",
    "    'epochs': [20]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Grid Search for Hyperparameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params: {params}\")\n",
    "    model = AdvancedConvFNO(modes=params['modes'], width=params['width'], conv_filters=params['conv_filters'])\n",
    "    val_loss = train_and_evaluate(model, train_loader, val_loader,\n",
    "                                  epochs=params['epochs'],\n",
    "                                  learning_rate=params['learning_rate'])\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Params: {best_params}, Best Validation Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Best Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_correct += torch.sum(torch.abs(outputs - targets) < 0.1).item()\n",
    "        test_total += targets.numel()\n",
    "\n",
    "test_accuracy = test_correct / test_total * 100\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Apply SINDy\n",
    "train_data_flat = train_data.reshape(-1, train_data.shape[-1])  # Flatten training data\n",
    "test_data_flat = test_data.reshape(-1, test_data.shape[-1])  # Flatten test data\n",
    "apply_sindy(train_data_flat, test_data_flat, dt=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
