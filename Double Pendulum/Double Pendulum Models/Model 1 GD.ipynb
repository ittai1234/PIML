{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.integrate import solve_ivp\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import pysindy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define double pendulum dynamics\n",
    "def double_pendulum(t, y, l1, l2, m1, m2, g):\n",
    "    theta1, z1, theta2, z2 = y\n",
    "    delta = theta2 - theta1\n",
    "    denom1 = (m1 + m2) * l1 - m2 * l1 * np.cos(delta) ** 2\n",
    "    denom2 = (l2 / l1) * denom1\n",
    "\n",
    "    dydt = np.zeros_like(y)\n",
    "    dydt[0] = z1\n",
    "    dydt[1] = (\n",
    "        (m2 * l1 * z1 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + m2 * g * np.sin(theta2) * np.cos(delta)\n",
    "         + m2 * l2 * z2 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta1))\n",
    "        / denom1\n",
    "    )\n",
    "    dydt[2] = z2\n",
    "    dydt[3] = (\n",
    "        (-m2 * l2 * z2 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + (m1 + m2) * g * np.sin(theta1) * np.cos(delta)\n",
    "         - (m1 + m2) * l1 * z1 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta2))\n",
    "        / denom2\n",
    "    )\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pendulums = 2000  # data set sizae\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset with second derivatives\n",
    "for _ in range(n_pendulums):\n",
    "    l1, l2 = np.random.uniform(0.5, 2.0, 2)\n",
    "    m1, m2 = np.random.uniform(0.5, 2.0, 2)\n",
    "    g = 9.81\n",
    "    y0 = np.random.uniform(-np.pi, np.pi, 4)\n",
    "    t_span = (0, 10)\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], 200)  # Finer temporal resolution\n",
    "    sol = solve_ivp(double_pendulum, t_span, y0, t_eval=t_eval, args=(l1, l2, m1, m2, g))\n",
    "    \n",
    "    theta1, theta1_dot, theta2, theta2_dot = sol.y\n",
    "    theta1_ddot = np.gradient(theta1_dot, t_eval)\n",
    "    theta2_ddot = np.gradient(theta2_dot, t_eval)\n",
    "    \n",
    "    X = np.vstack([theta1, theta2, theta1_dot, theta2_dot]).T  # Inputs: angles and angular velocities\n",
    "    y = np.vstack([theta1_ddot, theta2_ddot]).T               # Targets: angular accelerations\n",
    "    data.append((X, y, l1, l2, m1, m2, g))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_double_pendulum(example, save_path=None):\n",
    "    X, _, l1, l2, _, _, _ = example  # Skip 'y'\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Compute positions\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line, = ax.plot([], [], 'o-', lw=2)\n",
    "\n",
    "    def update(frame):\n",
    "        line.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        return line,\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize two examples\n",
    "visualize_double_pendulum(data[0], save_path='double_pendulum1.gif')\n",
    "visualize_double_pendulum(data[1], save_path='double_pendulum2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = np.vstack([example[0] for example in train_data])\n",
    "scaler.fit(X_train)\n",
    "\n",
    "train_data = [(scaler.transform(example[0]), *example[1:]) for example in train_data]\n",
    "val_data = [(scaler.transform(example[0]), *example[1:]) for example in val_data]\n",
    "test_data = [(scaler.transform(example[0]), *example[1:]) for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('extended_double_pendulum_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump({'train': train_data, 'val': val_data, 'test': test_data}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers, dropout_rate=0.2):\n",
    "        super(PINN, self).__init__()\n",
    "        self.input_layer = nn.Linear(layers[0], layers[1])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(1, len(layers) - 2):\n",
    "            self.hidden_layers.append(nn.Sequential(\n",
    "                nn.Linear(layers[i], layers[i + 1]),\n",
    "                nn.BatchNorm1d(layers[i + 1]),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ))\n",
    "        self.output_layer = nn.Linear(layers[-2], layers[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss functions\n",
    "def log_cosh_loss(y_pred, y_true):\n",
    "    diff = y_pred - y_true\n",
    "    return torch.mean(torch.log(torch.cosh(diff)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(y_pred, y_true, params_batch, X_batch):\n",
    "    l1, l2, m1, m2, g = params_batch\n",
    "    theta1, theta2, theta1_dot, theta2_dot = torch.split(X_batch, 1, dim=1)\n",
    "    theta1_ddot, theta2_ddot = torch.split(y_pred, 1, dim=1)\n",
    "\n",
    "    delta = theta2 - theta1\n",
    "    physics_term1 = (\n",
    "        (m2 * l1 * theta1_dot**2 * torch.sin(delta) * torch.cos(delta)\n",
    "         + m2 * g * torch.sin(theta2) * torch.cos(delta)\n",
    "         + m2 * l2 * theta2_dot**2 * torch.sin(delta)\n",
    "         - (m1 + m2) * g * torch.sin(theta1))\n",
    "        / ((m1 + m2) * l1 - m2 * l1 * torch.cos(delta)**2)\n",
    "    )\n",
    "    physics_term2 = (\n",
    "        (-m2 * l2 * theta2_dot**2 * torch.sin(delta) * torch.cos(delta)\n",
    "         + (m1 + m2) * g * torch.sin(theta1) * torch.cos(delta)\n",
    "         - (m1 + m2) * l1 * theta1_dot**2 * torch.sin(delta)\n",
    "         - (m1 + m2) * g * torch.sin(theta2))\n",
    "        / ((l2 / l1) * ((m1 + m2) * l1 - m2 * l1 * torch.cos(delta)**2))\n",
    "    )\n",
    "\n",
    "    loss = torch.mean((theta1_ddot - physics_term1)**2 + (theta2_ddot - physics_term2)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('extended_double_pendulum_dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['val']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_train = torch.tensor(np.vstack([example[0] for example in train_data]), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.vstack([example[1] for example in train_data]), dtype=torch.float32)\n",
    "params_train = torch.tensor([example[2:] for example in train_data], dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(np.vstack([example[0] for example in val_data]), dtype=torch.float32)\n",
    "y_val = torch.tensor(np.vstack([example[1] for example in val_data]), dtype=torch.float32)\n",
    "params_val = torch.tensor([example[2:] for example in val_data], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PINN\n",
    "model = PINN([4, 256, 256, 128, 64, 2])  # Increased depth and residual connections\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 100\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy metric for regression\n",
    "def compute_accuracy(y_pred, y_true, threshold=0.1):\n",
    "    # Calculate absolute error\n",
    "    error = torch.abs(y_pred - y_true)\n",
    "    # Count predictions within the threshold\n",
    "    within_threshold = (error < threshold).all(dim=1).float()\n",
    "    # Calculate percentage\n",
    "    accuracy = within_threshold.mean().item() * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 330.0924987792969, Val Loss: 294.4075622558594, Train Accuracy: 0.00%, Val Accuracy: 0.00%\n",
      "Epoch 2, Loss: 329.1801452636719, Val Loss: 294.2883605957031, Train Accuracy: 0.00%, Val Accuracy: 0.00%\n",
      "Epoch 3, Loss: 328.6101989746094, Val Loss: 294.1498718261719, Train Accuracy: 0.01%, Val Accuracy: 0.01%\n",
      "Epoch 4, Loss: 328.1043395996094, Val Loss: 293.9916076660156, Train Accuracy: 0.00%, Val Accuracy: 0.01%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_train) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m physics_loss(y_pred, y_train, params_train\u001b[38;5;241m.\u001b[39mT, X_train)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train) + 0.1 * physics_loss(y_pred, y_train, params_train.T, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = criterion(y_val_pred, y_val)\n",
    "        val_accuracy = compute_accuracy(y_val_pred, y_val)  # Calculate accuracy\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print metrics\n",
    "    train_accuracy = compute_accuracy(y_pred, y_train)  # Calculate training accuracy\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "test_data = torch.tensor(np.vstack([example[0] for example in test_data]), dtype=torch.float32)\n",
    "y_test = test_data[:, 2:]\n",
    "test_params = torch.tensor([example[1:] for example in test_data], dtype=torch.float32)\n",
    "\n",
    "y_test_pred = model(test_data)\n",
    "test_loss = criterion(y_test_pred, y_test)\n",
    "print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(example, model, scaler, save_path=None):\n",
    "    X, l1, l2, _, _, _ = example\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Predict using the model\n",
    "    X_tensor = torch.tensor(scaler.transform(X), dtype=torch.float32)\n",
    "    y_pred = model(X_tensor).detach().numpy()\n",
    "\n",
    "    theta1_pred, theta2_pred = y_pred[:, 0], y_pred[:, 1]\n",
    "\n",
    "    # Compute positions for ground truth\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    # Compute positions for predictions\n",
    "    x1_pred = l1 * np.sin(theta1_pred)\n",
    "    y1_pred = -l1 * np.cos(theta1_pred)\n",
    "    x2_pred = x1_pred + l2 * np.sin(theta2_pred)\n",
    "    y2_pred = y1_pred - l2 * np.cos(theta2_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line_true, = ax.plot([], [], 'o-', lw=2, label='Ground Truth')\n",
    "    line_pred, = ax.plot([], [], 'o--', lw=2, label='Prediction')\n",
    "    ax.legend()\n",
    "\n",
    "    def update(frame):\n",
    "        line_true.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        line_pred.set_data([0, x1_pred[frame], x2_pred[frame]], [0, y1_pred[frame], y2_pred[frame]])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize prediction vs ground truth for two examples\n",
    "visualize_prediction(test_data[0], model, scaler, save_path='prediction_vs_ground_truth1.gif')\n",
    "visualize_prediction(test_data[1], model, scaler, save_path='prediction_vs_ground_truth2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sindy(X, t):\n",
    "    # Use custom feature library for trigonometric functions\n",
    "    library = ps.PolynomialLibrary(degree=3) + ps.TrigonometricLibrary([1, 2])\n",
    "\n",
    "    # Use a lower threshold to capture more dynamics\n",
    "    optimizer = ps.STLSQ(threshold=0.05)\n",
    "\n",
    "    # Instantiate and fit SINDy model\n",
    "    sindy_model = ps.SINDy(feature_library=library, optimizer=optimizer, differentiation_method=ps.FiniteDifference())\n",
    "    sindy_model.fit(X, t=t)\n",
    "    return sindy_model\n",
    "\n",
    "# Prepare data for SINDy\n",
    "X_sindy = np.vstack([example[0] for example in train_data])\n",
    "t_sindy = np.linspace(0, 10, X_sindy.shape[0])\n",
    "\n",
    "# Train SINDy model\n",
    "sindy_model = train_sindy(X_sindy, t_sindy)\n",
    "\n",
    "# Display discovered equations\n",
    "sindy_model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SINDy predictions vs ground truth\n",
    "def visualize_sindy_prediction(example, sindy_model, scaler, save_path=None):\n",
    "    X, l1, l2, _, _, _ = example\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Predict using the SINDy model\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred = sindy_model.simulate(X_scaled[0], t=np.linspace(0, 10, X.shape[0]))\n",
    "\n",
    "    theta1_pred, theta2_pred = y_pred[:, 0], y_pred[:, 1]\n",
    "\n",
    "    # Compute positions for ground truth\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    # Compute positions for SINDy predictions\n",
    "    x1_pred = l1 * np.sin(theta1_pred)\n",
    "    y1_pred = -l1 * np.cos(theta1_pred)\n",
    "    x2_pred = x1_pred + l2 * np.sin(theta2_pred)\n",
    "    y2_pred = y1_pred - l2 * np.cos(theta2_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line_true, = ax.plot([], [], 'o-', lw=2, label='Ground Truth')\n",
    "    line_pred, = ax.plot([], [], 'o--', lw=2, label='SINDy Prediction')\n",
    "    ax.legend()\n",
    "\n",
    "    def update(frame):\n",
    "        line_true.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        line_pred.set_data([0, x1_pred[frame], x2_pred[frame]], [0, y1_pred[frame], y2_pred[frame]])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize SINDy prediction vs ground truth for two examples\n",
    "visualize_sindy_prediction(test_data[0], sindy_model, scaler, save_path='sindy_vs_ground_truth1.gif')\n",
    "visualize_sindy_prediction(test_data[1], sindy_model, scaler, save_path='sindy_vs_ground_truth2.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
