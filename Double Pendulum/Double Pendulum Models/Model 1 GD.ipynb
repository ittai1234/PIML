{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.integrate import solve_ivp\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import pysindy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define double pendulum dynamics\n",
    "def double_pendulum(t, y, l1, l2, m1, m2, g):\n",
    "    theta1, z1, theta2, z2 = y\n",
    "    delta = theta2 - theta1\n",
    "    denom1 = (m1 + m2) * l1 - m2 * l1 * np.cos(delta) ** 2\n",
    "    denom2 = (l2 / l1) * denom1\n",
    "\n",
    "    dydt = np.zeros_like(y)\n",
    "    dydt[0] = z1\n",
    "    dydt[1] = (\n",
    "        (m2 * l1 * z1 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + m2 * g * np.sin(theta2) * np.cos(delta)\n",
    "         + m2 * l2 * z2 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta1))\n",
    "        / denom1\n",
    "    )\n",
    "    dydt[2] = z2\n",
    "    dydt[3] = (\n",
    "        (-m2 * l2 * z2 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + (m1 + m2) * g * np.sin(theta1) * np.cos(delta)\n",
    "         - (m1 + m2) * l1 * z1 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta2))\n",
    "        / denom2\n",
    "    )\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pendulums = 5000  # data set sizae\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "for _ in range(n_pendulums):\n",
    "    l1, l2 = np.random.uniform(0.5, 2.0, 2)\n",
    "    m1, m2 = np.random.uniform(0.5, 2.0, 2)\n",
    "    g = 9.81\n",
    "    y0 = np.random.uniform(-np.pi, np.pi, 4)\n",
    "    t_span = (0, 10)\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], 200)  # Finer temporal resolution\n",
    "    sol = solve_ivp(double_pendulum, t_span, y0, t_eval=t_eval, args=(l1, l2, m1, m2, g))\n",
    "    \n",
    "    theta1, theta1_dot, theta2, theta2_dot = sol.y\n",
    "    X = np.vstack([theta1, theta2, theta1_dot, theta2_dot]).T\n",
    "    data.append((X, l1, l2, m1, m2, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize double pendulum motion\n",
    "def visualize_double_pendulum(example, save_path=None):\n",
    "    X, l1, l2, _, _, _ = example\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Compute positions\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line, = ax.plot([], [], 'o-', lw=2)\n",
    "\n",
    "    def update(frame):\n",
    "        line.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        return line,\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize two examples\n",
    "visualize_double_pendulum(train_data[0], save_path='double_pendulum1.gif')\n",
    "visualize_double_pendulum(train_data[1], save_path='double_pendulum2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = np.vstack([example[0] for example in train_data])\n",
    "scaler.fit(X_train)\n",
    "\n",
    "train_data = [(scaler.transform(example[0]), *example[1:]) for example in train_data]\n",
    "val_data = [(scaler.transform(example[0]), *example[1:]) for example in val_data]\n",
    "test_data = [(scaler.transform(example[0]), *example[1:]) for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('extended_double_pendulum_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump({'train': train_data, 'val': val_data, 'test': test_data}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PINN model class with Residual Connections\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.input_layer = nn.Linear(layers[0], layers[1])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(1, len(layers) - 2):\n",
    "            self.hidden_layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(layers[i + 1]))\n",
    "            self.hidden_layers.append(nn.SiLU())  # Swish activation\n",
    "        self.output_layer = nn.Linear(layers[-2], layers[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Physics-informed loss\n",
    "def physics_loss(y_pred, y_true, params_batch):\n",
    "    l1, l2, m1, m2, g = params_batch\n",
    "    theta1, theta2, theta1_dot, theta2_dot = torch.split(y_true, 1, dim=1)\n",
    "    theta1_ddot, theta2_ddot = torch.split(y_pred, 1, dim=1)\n",
    "\n",
    "    delta = theta2 - theta1\n",
    "    physics_term1 = (\n",
    "        (m2 * l1 * theta1_dot ** 2 * torch.sin(delta) * torch.cos(delta)\n",
    "         + m2 * g * torch.sin(theta2) * torch.cos(delta)\n",
    "         + m2 * l2 * theta2_dot ** 2 * torch.sin(delta)\n",
    "         - (m1 + m2) * g * torch.sin(theta1))\n",
    "        / ((m1 + m2) * l1 - m2 * l1 * torch.cos(delta) ** 2)\n",
    "    )\n",
    "    physics_term2 = (\n",
    "        (-m2 * l2 * theta2_dot ** 2 * torch.sin(delta) * torch.cos(delta)\n",
    "         + (m1 + m2) * g * torch.sin(theta1) * torch.cos(delta)\n",
    "         - (m1 + m2) * l1 * theta1_dot ** 2 * torch.sin(delta)\n",
    "         - (m1 + m2) * g * torch.sin(theta2))\n",
    "        / ((l2 / l1) * ((m1 + m2) * l1 - m2 * l1 * torch.cos(delta) ** 2))\n",
    "    )\n",
    "\n",
    "    loss = torch.mean((theta1_ddot - physics_term1) ** 2 + (theta2_ddot - physics_term2) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('extended_double_pendulum_dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['val']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_train = torch.tensor(np.vstack([example[0] for example in train_data]), dtype=torch.float32)\n",
    "y_train = X_train[:, 2:]  # Second derivatives as targets\n",
    "params_train = torch.tensor([example[1:] for example in train_data], dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(np.vstack([example[0] for example in val_data]), dtype=torch.float32)\n",
    "y_val = X_val[:, 2:]\n",
    "params_val = torch.tensor([example[1:] for example in val_data], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PINN\n",
    "model = PINN([4, 256, 256, 128, 64, 2])  # Increased depth and residual connections\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 100\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train) + 0.1 * physics_loss(y_pred, y_train, params_train.T)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = criterion(y_val_pred, y_val)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "test_data = torch.tensor(np.vstack([example[0] for example in test_data]), dtype=torch.float32)\n",
    "y_test = test_data[:, 2:]\n",
    "test_params = torch.tensor([example[1:] for example in test_data], dtype=torch.float32)\n",
    "\n",
    "y_test_pred = model(test_data)\n",
    "test_loss = criterion(y_test_pred, y_test)\n",
    "print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(example, model, scaler, save_path=None):\n",
    "    X, l1, l2, _, _, _ = example\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Predict using the model\n",
    "    X_tensor = torch.tensor(scaler.transform(X), dtype=torch.float32)\n",
    "    y_pred = model(X_tensor).detach().numpy()\n",
    "\n",
    "    theta1_pred, theta2_pred = y_pred[:, 0], y_pred[:, 1]\n",
    "\n",
    "    # Compute positions for ground truth\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    # Compute positions for predictions\n",
    "    x1_pred = l1 * np.sin(theta1_pred)\n",
    "    y1_pred = -l1 * np.cos(theta1_pred)\n",
    "    x2_pred = x1_pred + l2 * np.sin(theta2_pred)\n",
    "    y2_pred = y1_pred - l2 * np.cos(theta2_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line_true, = ax.plot([], [], 'o-', lw=2, label='Ground Truth')\n",
    "    line_pred, = ax.plot([], [], 'o--', lw=2, label='Prediction')\n",
    "    ax.legend()\n",
    "\n",
    "    def update(frame):\n",
    "        line_true.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        line_pred.set_data([0, x1_pred[frame], x2_pred[frame]], [0, y1_pred[frame], y2_pred[frame]])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize prediction vs ground truth for two examples\n",
    "visualize_prediction(test_data[0], model, scaler, save_path='prediction_vs_ground_truth1.gif')\n",
    "visualize_prediction(test_data[1], model, scaler, save_path='prediction_vs_ground_truth2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sindy(X, t):\n",
    "    # Use custom feature library for trigonometric functions\n",
    "    library = ps.PolynomialLibrary(degree=3) + ps.TrigonometricLibrary([1, 2])\n",
    "\n",
    "    # Use a lower threshold to capture more dynamics\n",
    "    optimizer = ps.STLSQ(threshold=0.05)\n",
    "\n",
    "    # Instantiate and fit SINDy model\n",
    "    sindy_model = ps.SINDy(feature_library=library, optimizer=optimizer, differentiation_method=ps.FiniteDifference())\n",
    "    sindy_model.fit(X, t=t)\n",
    "    return sindy_model\n",
    "\n",
    "# Prepare data for SINDy\n",
    "X_sindy = np.vstack([example[0] for example in train_data])\n",
    "t_sindy = np.linspace(0, 10, X_sindy.shape[0])\n",
    "\n",
    "# Train SINDy model\n",
    "sindy_model = train_sindy(X_sindy, t_sindy)\n",
    "\n",
    "# Display discovered equations\n",
    "sindy_model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SINDy predictions vs ground truth\n",
    "def visualize_sindy_prediction(example, sindy_model, scaler, save_path=None):\n",
    "    X, l1, l2, _, _, _ = example\n",
    "    theta1, theta2 = X[:, 0], X[:, 1]\n",
    "\n",
    "    # Predict using the SINDy model\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred = sindy_model.simulate(X_scaled[0], t=np.linspace(0, 10, X.shape[0]))\n",
    "\n",
    "    theta1_pred, theta2_pred = y_pred[:, 0], y_pred[:, 1]\n",
    "\n",
    "    # Compute positions for ground truth\n",
    "    x1 = l1 * np.sin(theta1)\n",
    "    y1 = -l1 * np.cos(theta1)\n",
    "    x2 = x1 + l2 * np.sin(theta2)\n",
    "    y2 = y1 - l2 * np.cos(theta2)\n",
    "\n",
    "    # Compute positions for SINDy predictions\n",
    "    x1_pred = l1 * np.sin(theta1_pred)\n",
    "    y1_pred = -l1 * np.cos(theta1_pred)\n",
    "    x2_pred = x1_pred + l2 * np.sin(theta2_pred)\n",
    "    y2_pred = y1_pred - l2 * np.cos(theta2_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line_true, = ax.plot([], [], 'o-', lw=2, label='Ground Truth')\n",
    "    line_pred, = ax.plot([], [], 'o--', lw=2, label='SINDy Prediction')\n",
    "    ax.legend()\n",
    "\n",
    "    def update(frame):\n",
    "        line_true.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n",
    "        line_pred.set_data([0, x1_pred[frame], x2_pred[frame]], [0, y1_pred[frame], y2_pred[frame]])\n",
    "        return line_true, line_pred\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta1), blit=True, interval=50)\n",
    "\n",
    "    if save_path:\n",
    "        ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Visualize SINDy prediction vs ground truth for two examples\n",
    "visualize_sindy_prediction(test_data[0], sindy_model, scaler, save_path='sindy_vs_ground_truth1.gif')\n",
    "visualize_sindy_prediction(test_data[1], sindy_model, scaler, save_path='sindy_vs_ground_truth2.gif')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
