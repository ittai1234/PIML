{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.integrate import solve_ivp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Pendulum Dynamics\n",
    "def regular_pendulum(t, y, l, g):\n",
    "    theta, z = y\n",
    "    dydt = np.zeros_like(y)\n",
    "    dydt[0] = z\n",
    "    dydt[1] = -(g / l) * np.sin(theta)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Workflow\n",
    "n_pendulums = 100\n",
    "output_dir = \"pendulum_video_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Dataset\n",
    "def generate_dataset(n_pendulums, dt, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dataset = []\n",
    "\n",
    "    for i in tqdm(range(n_pendulums), desc=\"Generating dataset\"):\n",
    "        l = np.random.uniform(0.5, 2.0)\n",
    "        g = 9.81\n",
    "        y0 = np.random.uniform(-np.pi, np.pi, 2)\n",
    "        t_span = (0, 10)\n",
    "        t_eval = np.linspace(t_span[0], t_span[1], int(10 / dt))\n",
    "\n",
    "        sol = solve_ivp(regular_pendulum, t_span, y0, t_eval=t_eval, args=(l, g), method='RK45')\n",
    "        data = sol.y[0]\n",
    "\n",
    "        gif_path = os.path.join(output_dir, f\"pendulum_{i}.gif\")\n",
    "        generate_gif(data, l, gif_path)\n",
    "\n",
    "        dataset.append((data, l, g, gif_path))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GIFs\n",
    "def generate_gif(data, l, save_path):\n",
    "    theta = data\n",
    "    x = l * np.sin(theta)\n",
    "    y = -l * np.cos(theta)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    line, = ax.plot([], [], 'o-', lw=2)\n",
    "\n",
    "    def update(frame):\n",
    "        line.set_data([0, x[frame]], [0, y[frame]])\n",
    "        return line,\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(theta), blit=True, interval=50)\n",
    "    ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset:   0%|          | 0/100 [00:00<?, ?it/s]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   1%|          | 1/100 [00:35<59:16, 35.93s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   2%|▏         | 2/100 [01:11<58:26, 35.78s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   3%|▎         | 3/100 [01:47<58:03, 35.92s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   4%|▍         | 4/100 [02:24<57:50, 36.15s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   5%|▌         | 5/100 [03:00<57:33, 36.36s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   6%|▌         | 6/100 [03:36<56:46, 36.24s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   7%|▋         | 7/100 [04:12<55:57, 36.10s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   8%|▊         | 8/100 [04:48<55:24, 36.14s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:   9%|▉         | 9/100 [05:24<54:37, 36.02s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  10%|█         | 10/100 [06:01<54:14, 36.16s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  11%|█         | 11/100 [06:37<53:42, 36.21s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  12%|█▏        | 12/100 [07:14<53:19, 36.36s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  13%|█▎        | 13/100 [07:51<52:56, 36.52s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  14%|█▍        | 14/100 [08:27<52:12, 36.43s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  15%|█▌        | 15/100 [09:04<51:52, 36.61s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  16%|█▌        | 16/100 [09:41<51:24, 36.72s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  17%|█▋        | 17/100 [10:18<51:06, 36.94s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  18%|█▊        | 18/100 [10:54<50:07, 36.68s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  19%|█▉        | 19/100 [11:31<49:23, 36.58s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  20%|██        | 20/100 [12:07<48:35, 36.44s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  21%|██        | 21/100 [12:44<48:04, 36.51s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  22%|██▏       | 22/100 [13:20<47:28, 36.52s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  23%|██▎       | 23/100 [13:58<47:16, 36.83s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  24%|██▍       | 24/100 [14:34<46:38, 36.82s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  25%|██▌       | 25/100 [15:11<45:49, 36.66s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  26%|██▌       | 26/100 [15:48<45:16, 36.72s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  27%|██▋       | 27/100 [16:24<44:37, 36.67s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  28%|██▊       | 28/100 [17:01<44:04, 36.73s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  29%|██▉       | 29/100 [17:38<43:40, 36.91s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  30%|███       | 30/100 [18:18<44:03, 37.76s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  31%|███       | 31/100 [18:57<43:58, 38.24s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  32%|███▏      | 32/100 [19:37<43:55, 38.76s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  33%|███▎      | 33/100 [20:15<42:52, 38.39s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  34%|███▍      | 34/100 [20:53<42:16, 38.43s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  35%|███▌      | 35/100 [21:31<41:17, 38.11s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  36%|███▌      | 36/100 [22:08<40:29, 37.97s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  37%|███▋      | 37/100 [22:45<39:32, 37.67s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  38%|███▊      | 38/100 [23:23<38:59, 37.73s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  39%|███▉      | 39/100 [24:01<38:14, 37.62s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  40%|████      | 40/100 [24:38<37:36, 37.60s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  41%|████      | 41/100 [25:15<36:39, 37.27s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  42%|████▏     | 42/100 [25:52<36:07, 37.38s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  43%|████▎     | 43/100 [26:29<35:14, 37.09s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  44%|████▍     | 44/100 [27:07<34:48, 37.29s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  45%|████▌     | 45/100 [27:45<34:28, 37.60s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  46%|████▌     | 46/100 [28:25<34:27, 38.29s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  47%|████▋     | 47/100 [29:03<33:50, 38.30s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  48%|████▊     | 48/100 [29:41<33:07, 38.23s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  49%|████▉     | 49/100 [30:21<32:51, 38.65s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  50%|█████     | 50/100 [30:58<31:51, 38.24s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  51%|█████     | 51/100 [31:35<30:52, 37.80s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  52%|█████▏    | 52/100 [32:12<30:08, 37.68s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  53%|█████▎    | 53/100 [32:50<29:30, 37.67s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  54%|█████▍    | 54/100 [33:27<28:50, 37.63s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  55%|█████▌    | 55/100 [34:07<28:45, 38.35s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  56%|█████▌    | 56/100 [34:44<27:49, 37.94s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  57%|█████▋    | 57/100 [35:22<27:01, 37.71s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  58%|█████▊    | 58/100 [36:00<26:38, 38.07s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  59%|█████▉    | 59/100 [36:41<26:27, 38.72s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  60%|██████    | 60/100 [37:18<25:37, 38.43s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  61%|██████    | 61/100 [37:55<24:39, 37.94s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  62%|██████▏   | 62/100 [38:33<23:58, 37.84s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  63%|██████▎   | 63/100 [39:10<23:09, 37.55s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  64%|██████▍   | 64/100 [39:47<22:33, 37.61s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  65%|██████▌   | 65/100 [40:24<21:47, 37.37s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  66%|██████▌   | 66/100 [41:01<21:05, 37.23s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  67%|██████▋   | 67/100 [41:39<20:33, 37.39s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  68%|██████▊   | 68/100 [42:18<20:09, 37.80s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  69%|██████▉   | 69/100 [42:54<19:20, 37.43s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  70%|███████   | 70/100 [43:31<18:37, 37.26s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  71%|███████   | 71/100 [44:08<17:55, 37.10s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  72%|███████▏  | 72/100 [44:44<17:11, 36.83s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  73%|███████▎  | 73/100 [45:21<16:39, 37.00s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  74%|███████▍  | 74/100 [45:59<16:08, 37.24s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  75%|███████▌  | 75/100 [46:37<15:31, 37.24s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  76%|███████▌  | 76/100 [47:14<14:56, 37.34s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  77%|███████▋  | 77/100 [47:51<14:14, 37.15s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  78%|███████▊  | 78/100 [48:28<13:34, 37.04s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  79%|███████▉  | 79/100 [49:06<13:03, 37.30s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  80%|████████  | 80/100 [49:42<12:19, 36.95s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  81%|████████  | 81/100 [50:19<11:42, 36.95s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  82%|████████▏ | 82/100 [50:55<11:01, 36.74s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  83%|████████▎ | 83/100 [51:32<10:25, 36.80s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  84%|████████▍ | 84/100 [52:09<09:49, 36.84s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  85%|████████▌ | 85/100 [52:45<09:11, 36.78s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  86%|████████▌ | 86/100 [53:22<08:35, 36.81s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  87%|████████▋ | 87/100 [53:59<07:58, 36.79s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  88%|████████▊ | 88/100 [54:35<07:19, 36.60s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  89%|████████▉ | 89/100 [55:11<06:41, 36.51s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  90%|█████████ | 90/100 [55:52<06:17, 37.77s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  91%|█████████ | 91/100 [56:32<05:44, 38.28s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  92%|█████████▏| 92/100 [57:08<05:00, 37.62s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  93%|█████████▎| 93/100 [57:44<04:21, 37.30s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  94%|█████████▍| 94/100 [58:20<03:41, 36.89s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  95%|█████████▌| 95/100 [58:56<03:03, 36.71s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  96%|█████████▌| 96/100 [59:33<02:27, 36.78s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  97%|█████████▋| 97/100 [1:00:10<01:50, 36.69s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  98%|█████████▊| 98/100 [1:00:46<01:13, 36.55s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset:  99%|█████████▉| 99/100 [1:01:23<00:36, 36.73s/it]MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Generating dataset: 100%|██████████| 100/100 [1:02:00<00:00, 37.20s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = generate_dataset(n_pendulums, dt=0.01, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "class PendulumDataset(Dataset):\n",
    "    def __init__(self, dataset, seq_len, pred_len):\n",
    "        self.dataset = dataset\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, l, g, gif_path = self.dataset[idx]\n",
    "\n",
    "        gif = Image.open(gif_path)\n",
    "        frames = []\n",
    "        try:\n",
    "            while True:\n",
    "                frame = gif.convert(\"RGB\")\n",
    "                frames.append(np.array(frame))\n",
    "                gif.seek(gif.tell() + 1)\n",
    "        except EOFError:\n",
    "            pass\n",
    "\n",
    "        positions = np.column_stack([data])\n",
    "\n",
    "        input_seq = positions[:self.seq_len]\n",
    "        target_seq = positions[self.seq_len:self.seq_len + self.pred_len]\n",
    "\n",
    "        return torch.tensor(input_seq, dtype=torch.float32), torch.tensor(target_seq, dtype=torch.float32), gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 90\n",
    "pred_len = 10\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = PendulumDataset(train_data, seq_len, pred_len)\n",
    "val_dataset = PendulumDataset(val_data, seq_len, pred_len)\n",
    "test_dataset = PendulumDataset(test_data, seq_len, pred_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class LSTMPendulumPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMPendulumPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets, _ in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Prediction GIFs\n",
    "def generate_prediction_gif(model, test_loader, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, targets, gif_path) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            predictions = model(inputs).squeeze(0).numpy()\n",
    "\n",
    "        true_positions = targets.numpy()\n",
    "        input_positions = inputs.squeeze(0).numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.set_xlim(-2.5, 2.5)\n",
    "        ax.set_ylim(-2.5, 2.5)\n",
    "        ax.set_aspect('equal')\n",
    "        true_line, = ax.plot([], [], 'o-', lw=2, label='True Motion')\n",
    "        pred_line, = ax.plot([], [], 'o-', lw=2, linestyle='--', label='Predicted Motion')\n",
    "\n",
    "        def update(frame):\n",
    "            if frame < len(input_positions):\n",
    "                true_line.set_data([0, input_positions[frame]],\n",
    "                                   [0, input_positions[frame]])\n",
    "            else:\n",
    "                idx = frame - len(input_positions)\n",
    "                true_line.set_data([0, true_positions[idx]],\n",
    "                                   [0, true_positions[idx]])\n",
    "                pred_line.set_data([0, predictions[idx]],\n",
    "                                   [0, predictions[idx]])\n",
    "            return true_line, pred_line\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=len(input_positions) + len(true_positions), blit=True, interval=50)\n",
    "        ani.save(os.path.join(output_dir, f\"prediction_{i}.gif\"), fps=20, writer='imagemagick')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMPendulumPredictor(input_dim, hidden_dim, output_dim, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32, 10, 1])) that is different to the input size (torch.Size([32, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/20:  67%|██████▋   | 2/3 [02:56<01:27, 87.83s/it]C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([16, 10, 1])) that is different to the input size (torch.Size([16, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/20: 100%|██████████| 3/3 [03:40<00:00, 73.48s/it]\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([10, 10, 1])) that is different to the input size (torch.Size([10, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 3.1426893870035806, Val Loss: 6.685717582702637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3/3 [03:43<00:00, 74.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.8521271546681723, Val Loss: 6.368018627166748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 3/3 [03:44<00:00, 74.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 3.2911338011423745, Val Loss: 5.957829475402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 3/3 [03:41<00:00, 73.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.7799422343571982, Val Loss: 5.4502434730529785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 3/3 [03:56<00:00, 78.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 2.578622261683146, Val Loss: 4.793635845184326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 3/3 [03:48<00:00, 76.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1.7274532318115234, Val Loss: 4.036993503570557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  33%|███▎      | 1/3 [01:42<03:24, 102.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mPendulumDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m         frame \u001b[38;5;241m=\u001b[39m \u001b[43mgif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         frames\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(frame))\n\u001b[0;32m     20\u001b[0m         gif\u001b[38;5;241m.\u001b[39mseek(gif\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:1068\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     dither \u001b[38;5;241m=\u001b[39m Dither\u001b[38;5;241m.\u001b[39mFLOYDSTEINBERG\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;66;03m# normalize source image and try again\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_gif(model, test_loader, output_dir=\"predicted_gifs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
