{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "G = 9.81  # Gravity (m/s^2)\n",
    "BOUNCE_COEFF = 0.9  # Coefficient of restitution (energy retention on bounce)\n",
    "dt = 0.01\n",
    "mass = 1.0\n",
    "radius = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_balls = 100\n",
    "seq_len = 80\n",
    "pred_len = 20\n",
    "box_size = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 16\n",
    "hidden_dim = 64\n",
    "sparse_dim = 8\n",
    "fourier_modes = 16\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "alpha, beta, gamma = 0.1, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Handling\n",
    "def handle_collisions(state, radius, box_size, bounce_coeff):\n",
    "    x, vx, y, vy = state\n",
    "    if x - radius < -box_size:\n",
    "        x = -box_size + radius\n",
    "        vx = -bounce_coeff * vx\n",
    "    elif x + radius > box_size:\n",
    "        x = box_size - radius\n",
    "        vx = -bounce_coeff * vx\n",
    "    if y - radius < -box_size:\n",
    "        y = -box_size + radius\n",
    "        vy = -bounce_coeff * vy\n",
    "    elif y + radius > box_size:\n",
    "        y = box_size - radius\n",
    "        vy = -bounce_coeff * vy\n",
    "    return np.array([x, vx, y, vy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle Dynamics\n",
    "def particle_dynamics_with_collisions(t, y, mass, radius, box_size, drag_coeff, bounce_coeff):\n",
    "    x, vx, y, vy = y\n",
    "    dydt = np.zeros_like(y)\n",
    "    dydt[0] = vx\n",
    "    dydt[2] = vy\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    drag_force_x = -drag_coeff * speed * vx\n",
    "    drag_force_y = -drag_coeff * speed * vy\n",
    "    dydt[1] = drag_force_x / mass\n",
    "    dydt[3] = (-G + drag_force_y / mass)\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Generation\n",
    "def generate_ball_dataset(n_balls, dt, seq_len, pred_len, box_size=5.0):\n",
    "    trajectories = []\n",
    "    for _ in tqdm(range(n_balls), desc=\"Generating dataset\"):\n",
    "        mass = np.random.uniform(0.5, 5.0)\n",
    "        radius = np.random.uniform(0.05, 0.2)\n",
    "        drag_coeff = 0.1\n",
    "        bounce_coeff = 0.9\n",
    "        init_pos = np.random.uniform(-box_size + radius, box_size - radius, 2)\n",
    "        init_vel = np.random.uniform(-5.0, 5.0, 2)\n",
    "        y0 = np.concatenate([init_pos, init_vel])\n",
    "        t_eval = np.linspace(0, (seq_len + pred_len) * dt, seq_len + pred_len)\n",
    "        trajectory = []\n",
    "        state = y0\n",
    "        for t in t_eval:\n",
    "            sol = solve_ivp(\n",
    "                particle_dynamics_with_collisions,\n",
    "                (t, t + dt),\n",
    "                state,\n",
    "                args=(mass, radius, box_size, drag_coeff, bounce_coeff),\n",
    "                method=\"RK45\",\n",
    "                t_eval=[t + dt],\n",
    "            )\n",
    "            state = sol.y.flatten()\n",
    "            state = handle_collisions(state, radius, box_size, bounce_coeff)\n",
    "            trajectory.append(state)\n",
    "        trajectories.append(np.array(trajectory))\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "trajectories = generate_ball_dataset(n_balls, dt, seq_len + pred_len, box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class BallTrajectoryDataset(Dataset):\n",
    "    def __init__(self, trajectories, seq_len, pred_len):\n",
    "        self.trajectories = trajectories\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "        input_seq = trajectory[:self.seq_len]\n",
    "        target_seq = trajectory[self.seq_len:self.seq_len + self.pred_len]\n",
    "        return torch.tensor(input_seq, dtype=torch.float32), torch.tensor(target_seq, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Trajectory GIFs\n",
    "def save_trajectory_gif(trajectory, radius, box_size, save_path, title=\"Trajectory\"):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(-box_size, box_size)\n",
    "    ax.set_ylim(-box_size, box_size)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ball = plt.Circle((trajectory[0, 0], trajectory[0, 2]), radius, fc='blue')\n",
    "    ax.add_patch(ball)\n",
    "\n",
    "    def update(frame):\n",
    "        ball.set_center((trajectory[frame, 0], trajectory[frame, 2]))\n",
    "        return ball,\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(trajectory), blit=True, interval=50)\n",
    "    ani.save(save_path, fps=20, writer='imagemagick')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Best and Worst Predictions\n",
    "def save_best_worst_predictions(predictions, targets, losses, folder, radius, box_size, mode):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    real_folder = os.path.join(folder, \"real_movement\")\n",
    "    predicted_folder = os.path.join(folder, \"predicted_movement\")\n",
    "    os.makedirs(real_folder, exist_ok=True)\n",
    "    os.makedirs(predicted_folder, exist_ok=True)\n",
    "\n",
    "    sorted_indices = np.argsort(losses)\n",
    "    best_indices = sorted_indices[:5]\n",
    "    worst_indices = sorted_indices[-5:]\n",
    "\n",
    "    for idx in best_indices:\n",
    "        save_trajectory_gif(targets[idx][-len(targets[idx]) // 5:], radius, box_size, os.path.join(real_folder, f\"{mode}_best_real_{idx}.gif\"), \"True Trajectory (Best)\")\n",
    "        save_trajectory_gif(predictions[idx][-len(predictions[idx]) // 5:], radius, box_size, os.path.join(predicted_folder, f\"{mode}_best_predicted_{idx}.gif\"), \"Predicted Trajectory (Best)\")\n",
    "\n",
    "    for idx in worst_indices:\n",
    "        save_trajectory_gif(targets[idx][-len(targets[idx]) // 5:], radius, box_size, os.path.join(real_folder, f\"{mode}_worst_real_{idx}.gif\"), \"True Trajectory (Worst)\")\n",
    "        save_trajectory_gif(predictions[idx][-len(predictions[idx]) // 5:], radius, box_size, os.path.join(predicted_folder, f\"{mode}_worst_predicted_{idx}.gif\"), \"Predicted Trajectory (Worst)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save All Test Predictions\n",
    "def save_all_test_predictions(predictions, targets, folder, radius, box_size):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    real_folder = os.path.join(folder, \"real_movement\")\n",
    "    predicted_folder = os.path.join(folder, \"predicted_movement\")\n",
    "    os.makedirs(real_folder, exist_ok=True)\n",
    "    os.makedirs(predicted_folder, exist_ok=True)\n",
    "\n",
    "    for idx in range(len(predictions)):\n",
    "        save_trajectory_gif(targets[idx][-len(targets[idx]) // 5:], radius, box_size, os.path.join(real_folder, f\"test_real_{idx}.gif\"), \"True Trajectory\")\n",
    "        save_trajectory_gif(predictions[idx][-len(predictions[idx]) // 5:], radius, box_size, os.path.join(predicted_folder, f\"test_predicted_{idx}.gif\"), \"Predicted Trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model\n",
    "class SINDyKoopmanFNO(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim, sparse_dim, fourier_modes):\n",
    "        super(SINDyKoopmanFNO, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "        )\n",
    "        self.koopman = nn.Linear(latent_dim, latent_dim, bias=False)\n",
    "        self.sindy_dynamics = nn.Linear(latent_dim, sparse_dim, bias=False)\n",
    "        self.fourier_layer = nn.Sequential(\n",
    "            nn.Linear(latent_dim, fourier_modes),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fourier_modes, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_next = self.koopman(z)\n",
    "        dzdt = self.sindy_dynamics(z)\n",
    "        z_fourier = self.fourier_layer(z)\n",
    "        z_combined = z_next + z_fourier\n",
    "        x_reconstructed = self.decoder(z_combined)\n",
    "        return x_reconstructed, z_next, dzdt, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "def compute_energy(state, mass, g):\n",
    "    vx, vy = state[:, :, 1], state[:, :, 3]\n",
    "    y = state[:, :, 2]\n",
    "    kinetic_energy = 0.5 * mass * (vx**2 + vy**2)\n",
    "    potential_energy = mass * g * y\n",
    "    return kinetic_energy + potential_energy\n",
    "\n",
    "def energy_loss(predicted_state, true_state, mass, g):\n",
    "    predicted_energy = compute_energy(predicted_state, mass, g)\n",
    "    true_energy = compute_energy(true_state, mass, g)\n",
    "    return torch.mean((predicted_energy - true_energy)**2)\n",
    "\n",
    "def combined_loss(x_reconstructed, x_target, z_next, dzdt, z_pred, mass, g, alpha=0.1, beta=0.1, gamma=0.1):\n",
    "    reconstruction_loss = torch.mean((x_reconstructed - x_target)**2)\n",
    "    koopman_loss = torch.mean((z_next - z_pred)**2)\n",
    "    sparse_loss = torch.mean((dzdt - z_pred)**2)\n",
    "    energy_loss_value = energy_loss(x_reconstructed, x_target, mass, g)\n",
    "    return reconstruction_loss + alpha * energy_loss_value + beta * koopman_loss + gamma * sparse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Splitting\n",
    "def split_dataset(trajectories, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.\"\n",
    "    train_val_data, test_data = train_test_split(trajectories, test_size=test_ratio, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_val_data, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = split_dataset(trajectories)\n",
    "train_dataset = BallTrajectoryDataset(train_set, seq_len, pred_len)\n",
    "val_dataset = BallTrajectoryDataset(val_set, seq_len, pred_len)\n",
    "test_dataset = BallTrajectoryDataset(test_set, seq_len, pred_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation\n",
    "def train_and_save_predictions(model, train_loader, val_loader, optimizer, mass, g, num_epochs, alpha, beta, gamma, radius, box_size):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss, total_train_acc = 0.0, 0.0\n",
    "        total_val_loss, total_val_acc = 0.0, 0.0\n",
    "        train_predictions, train_targets, train_losses = [], [], []\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_reconstructed, z_next, dzdt, z = model(inputs)\n",
    "            z_pred = model.koopman(z)\n",
    "            loss = combined_loss(x_reconstructed, targets, z_next, dzdt, z_pred, mass, g, alpha, beta, gamma)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            train_acc = 1 - (torch.norm(x_reconstructed - targets) / torch.norm(targets))\n",
    "            total_train_acc += train_acc.item()\n",
    "\n",
    "            train_predictions.append(x_reconstructed.detach().cpu().numpy())\n",
    "            train_targets.append(targets.detach().cpu().numpy())\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        val_predictions, val_targets, val_losses = [], [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                x_reconstructed, z_next, dzdt, z = model(inputs)\n",
    "                z_pred = model.koopman(z)\n",
    "                loss = combined_loss(x_reconstructed, targets, z_next, dzdt, z_pred, mass, g, alpha, beta, gamma)\n",
    "                total_val_loss += loss.item()\n",
    "                val_acc = 1 - (torch.norm(x_reconstructed - targets) / torch.norm(targets))\n",
    "                total_val_acc += val_acc.item()\n",
    "\n",
    "                val_predictions.append(x_reconstructed.detach().cpu().numpy())\n",
    "                val_targets.append(targets.detach().cpu().numpy())\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {total_train_loss / len(train_loader):.4f}, Train Accuracy: {total_train_acc / len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {total_val_loss / len(val_loader):.4f}, Val Accuracy: {total_val_acc / len(val_loader):.4f}\")\n",
    "\n",
    "        if epoch == num_epochs - 1:\n",
    "            save_best_worst_predictions(np.concatenate(train_predictions), np.concatenate(train_targets), train_losses, \"training_predictions\", radius, box_size, \"train\")\n",
    "            save_best_worst_predictions(np.concatenate(val_predictions), np.concatenate(val_targets), val_losses, \"val_predictions\", radius, box_size, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = SINDyKoopmanFNO(input_dim=4, latent_dim=latent_dim, hidden_dim=hidden_dim, sparse_dim=sparse_dim, fourier_modes=fourier_modes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_and_save_predictions(model, train_loader, val_loader, optimizer, mass, G, num_epochs, alpha, beta, gamma, radius, box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Evaluation\n",
    "def evaluate_and_save_test_predictions(model, test_loader, mass, g, radius, box_size):\n",
    "    model.eval()\n",
    "    test_predictions, test_targets = [], []\n",
    "    total_test_loss, total_test_acc = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            x_reconstructed, z_next, dzdt, z = model(inputs)\n",
    "            loss = combined_loss(x_reconstructed, targets, z_next, dzdt, z, mass, g)\n",
    "            total_test_loss += loss.item()\n",
    "            test_acc = 1 - (torch.norm(x_reconstructed - targets) / torch.norm(targets))\n",
    "            total_test_acc += test_acc.item()\n",
    "\n",
    "            test_predictions.append(x_reconstructed.detach().cpu().numpy())\n",
    "            test_targets.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    avg_test_acc = total_test_acc / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.4f}\")\n",
    "\n",
    "    save_all_test_predictions(np.concatenate(test_predictions), np.concatenate(test_targets), folder=\"test_predictions\", radius=radius, box_size=box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_and_save_test_predictions(model, test_loader, mass, G, radius, box_size)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
